---
header-includes:
- \usepackage{longtable}
- \usepackage[utf8]{inputenc}
- \usepackage[spanish]{babel}\decimalpoint
- \setlength{\parindent}{1.25cm}
- \usepackage{amsmath}
- \usepackage{array}
- \usepackage{float}
- \usepackage{multirow}
output:
  pdf_document:
    number_sections: yes
  word_document: default
fontsize: 12pt
papersize: letter
geometry: margin = 1in
language: es
editor_options:
  markdown:
    wrap: 72
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = F, fig.align = "center", fig.pos = "H")
library(kableExtra)
library(knitr)
library(leaps)
source("Functions.R")
library(tidyverse)
```

```{=tex}
\input{titlepage}
\thispagestyle{empty}
\tableofcontents
\newpage
\thispagestyle{empty}
\listoffigures
\listoftables
\newpage
```

```{=tex}
\pagestyle{myheadings}
\setcounter{page}{3}
```

\section{Pregunta 1}

Teniendo en cuenta la base de datos brindada, en la cual hay 5 variables regresoras dadas por: 
$$Y_i = \beta_0 + \beta_1 X_{1i} + \beta_2 X_{2i} + \beta_3 X_{3i} + \beta_4 X_{4i} + \beta_5X_{5i}+ \varepsilon_i, \ \varepsilon_i \stackrel{\text{iid}}{\sim} N(0, \sigma^2); \ 1 \leqslant i \leqslant 113$$
Donde ... acá dicen el nombre de las variables

\begin{itemize}
  \item Y: Hospitales
  \item $X_1$:
\end{itemize}

```{r}
datos <- read.table("EquipoXX.txt", header = T)
modelo <- lm(Y ~ ., data = datos)
betas <- round(coef(modelo), 4)
betas1 <- as.data.frame(betas)
```
\subsection{Modelo de regresión}

Al ajustar el modelo, se  obtienen los  siguientes coeficientes:

```{r}
rownames(betas1) <- c("$\\beta_0$", "$\\beta_1$", "$\\beta_2$", "$\\beta_3$", "$\\beta_4$", "$\\beta_5$")
betas1 %>% 
  kable(col.names = c("Valor del parámetro"), caption = "Tabla de valores coeficientes del modelo", escape = F, booktab = T, align = "c", row.names = T) %>% 
  kable_styling(latex_options = c("HOLD_position"))
```
Por lo tanto, el modelo de regresión ajustado es:
$$\hat{Y}_i = `r betas[1]` + `r betas[2]` X_{1i} + `r betas[3]` X_{2i} + `r betas[4]` X_{3i} +`r betas[5]` X_{4i} + `r betas[6]`X_{5i} +\varepsilon_i, \ \varepsilon_i \stackrel{\text{iid}}{\sim} N(0, \sigma^2); \ 1 \leqslant i \leqslant 113$$
\subsection{Significancia de la regresión}
Para analizar la significancia de la regresión, se plantea el siguiente juego de hipótesis:
$$
\begin{cases}
  \begin{aligned}
    H_0&: \beta_0 =\beta_1=\beta_2=\beta_3=\beta_4=\beta_5=0 \\
    H_a&: \text{Algún }\beta_j \text{ distinto de 0 para j=1, 2,..., 5}
  \end{aligned}
\end{cases}
$$

Cuyo estadístico de prueba es:

\begin{equation}
F_0 = \frac{MST}{MSE} \stackrel{H_0}{\sim} f_{5, `r nrow(datos)-6`}\\
\end{equation}

Ahora, se presenta la tabla Anova:
```{r}
tabla.anova <- myAnova(modelo)
rownames(tabla.anova) <- c("Regresión", "Error")
tabla.anova %>% 
  kable(col.names = c("Sumas de cuadrados", "g.l.", "Cuadrado medio", "$F_0$", "P-valor"),caption = "Tabla  ANOVA para el modelo", escape=F, booktab=T, align = "c", row.names = T) %>% 
  kable_styling(latex_options = c("HOLD_position"))
```
De la tabla Anova, se observa un valor P aproximadamente igual a 1, por lo  que se rechaza la hipótesis nula en la que $\beta_j = 0$ con $0 \leqslant j \leqslant 5$, aceptando la hipótesis alternativa en la que algún $\beta_j \neq 0$, por lo tanto la regresión es significativa. 

\subsection{Significancia  de los parámetros}
En el siguiente cuadro se presenta información de los parámetros, la cual permitirá determinar cuáles de ellos son significativos.

```{r}
tabla.coeficientes <- summary(modelo)$coefficients
rownames(tabla.coeficientes) <- paste("$\\beta_", 0:5, "$", sep = "")
tabla.coeficientes %>% 
  kable(col.names = c("$\\hat{\\beta_j}$", "$SE(\\hat{\\beta_j})$", "$T_{0j}$", "P-valor"),caption = "Resumen de los coeficientes", escape=F, booktab=T, align = "c", row.names = T, digits = 4) %>% 
  kable_styling(latex_options = c("HOLD_position"))
```
Los P-valores presentes en la tabla permiten concluir que con un nivel de significancia $\alpha = 0.05$, los parámetros $\beta_i$ y $\beta_j$ son significativos, pues sus P-valores son menores a $\alpha$.

\subsection{Interpretación de los parámetros}

Interpreten sólo los parámetros significativos, respecto a $\beta_0$ ya saben que se debe cumplir que el 0 esté en el intervalo

\textbf{$\hat{\beta_i}$:} 

\textbf{$\hat{\beta_j}$:} 

\textbf{$\hat{\beta_2}$:} 

\subsection{Coeficiente de determinación múltiple $R^2$}

El  modelo tiene un coeficiente de determinación múltiple $R^2 = 0.hey$, lo que significa que aproximadamente el $hey\%$ de la variabilidad total  observada en la respuesta es explicada por el modelo de regresión propuesto en el presente informe.


\section{Pregunta 2}
\subsection{Planteamiento pruebas de hipótesis  y modelo reducido}

Las covariable con el P-valor más alto en el modelo fueron $X_1, X_2, X_4$, por lo tanto a través de la tabla de todas las regresiones posibles se pretende hacer la siguiente prueba de hipótesis:

$$
\begin{cases}
\begin{aligned}
\text{H}_0&: \beta_1 =\beta_2 = \beta_4 = 0\\
\text{H}_1&: \text{Algún } \beta_j \text{ distinto de 0 para } j=1, 2, 4
\end{aligned}
\end{cases}
$$

```{r}
todas.regresiones <- myAllRegTable(modelo)
todas.regresiones <- todas.regresiones[c(31, 9), c(4, 6)]
row.names(todas.regresiones) <- c("Modelo  completo", "Modelo reducido")
todas.regresiones %>% 
    kable(col.names = c("$SSE$", "Covariables en el modelo"), caption = "Resumen tabla de todas las regresiones", escape=F, booktab=T, align = "c", row.names = T, digits = 4) %>% 
  kable_styling(latex_options = c("HOLD_position"))
```
Luego un modelo reducido para la prueba de significancia del subconjunto es:

$$Y_i = \beta_0 + \beta_3 X_{3i} + \beta_5 X_{5i} + \varepsilon; \ \varepsilon_i \stackrel{\text{iid}}{\sim} N(0, \sigma^2); \ 1 \leqslant i \leqslant 113$$
\subsection{Estadístico de prueba y conclusión}
Se construye el estadístico de prueba como:

\begin{equation}
\begin{split}
F_0 &= \frac{(SSE(\beta_0, \beta_3, \beta_5) - SSE(\beta_0, \ \cdots, \ \beta_5))/3}{MSE(\beta_0, \ \cdots, \ \beta_5)} \stackrel{H_0}{\sim} f_{3, `r nrow(datos)-6`}\\
&= \frac{numerador}{denominador} \\
&= final
\end{split}
\end{equation}

Ahora, comparando el $F_0$ con $f_{0.95, 3, `r nrow(datos)-6`} = `r round(qf(0.95, 3, nrow(datos)-6), 4)`$, se puede ver que $F_0 ? f_{0.95, 1, 45}$ y por tanto qué se rechaza ...

Es posible o no descartar las variables del subconjunto?

\section{Pregunta 3}
\subsection{Prueba de hipótesis y prueba de hipótesis  matricial}
Se hace la pregunta si ¿...? por consiguiente se plantea la siguiente prueba de hipótesis:

$$
\begin{cases}
\begin{aligned}
\text{H}_0&: \beta_2 = 3\beta_3; \ \beta_2  = \beta_4 \\
\text{H}_1&: \text{Alguna de las igualdades no se cumple}
\end{aligned}
\end{cases}
$$

reescribiendo matricialmente:
$$
\begin{cases}
\begin{aligned}
\text{H}_0&: \mathbf{L} \underline{\mathbf{\beta}} = \underline{\mathbf{0}} \\
\text{H}_1&: \mathbf{L} \underline{\mathbf{\beta}} \neq \underline{\mathbf{0}} \\
\end{aligned}
\end{cases}
$$

Con $\mathbf{L}$ dada por

$$
L = \begin{bmatrix}
  0 & 1 & 0 & -3 & 0 & 0\\
  0 & 0 & 1 & 0 & -1 & 0 \\
\end{bmatrix}
$$

El modelo reducido está dado por: 

$$Y_i = \beta_o  + \beta_2 X^*_{2i}+ \beta_3 X^*_{3i} + \beta_5 X_{5i}+\varepsilon_i, \ \varepsilon_i \stackrel{\text{iid}}{\sim} N(0, \sigma^2); \ 1 \leqslant i \leqslant 113$$

Donde $X^*_{2i} = X_{2i} + X_{4i}$ y $X^*_{3i} = 3X_{1i} + X_{3i}$

\textbf{Nota:} NO usen esta misma prueba

\subsection{Estadístico de prueba}

El estadístico de prueba $F_0$ está dado por:

\begin{equation}
F_0 = \frac{(SSE(MR) - SSE(MF))/2}{MSE(MF)} \stackrel{H_0}{\sim} f_{100, `r nrow(datos)-6`}\\
\end{equation}

Aquí deben igualar después esa ecuación a sí misma con los valores conocidos reemplazados, es decir, el SSE(MF) y el MSE(MF).

\section{Pregunta 4}

\subsection{Supuestos del modelo}

\subsubsection{Normalidad de los residuales}

Para la validación de este supuesto, se planteará la siguiente prueba de hipótesis que se realizará por medio de shapiro-wilk, acompañada de un gráfico cuantil-cuantil:
$$
\begin{cases}
\begin{aligned}
  \text{H}_0&: \varepsilon_i \sim \text{Normal}\\
  \text{H}_1&: \varepsilon_i \nsim \text{Normal}
\end{aligned}
\end{cases}
$$
```{r fig.cap = "Gráfico cuantil-cuantil y normalidad de residuales"} 
myQQnorm(modelo, xlab = "Cuantiles teóricos",
         ylab = "Cuantiles muestrales", pch=20)
```

Al ser el P-valor aproximadamente igual a 0.4462 y teniendo en cuenta que el nivel de significancia $\alpha = 0.05$, el P-valor es mucho mayor y por lo tanto, no se rechazaría la hipótesis nula, es decir que los datos distribuyen normal con media $\mu$ y varianza $\sigma^2$, sin embargo la gráfica de comparación de cuantiles permite ver colas más pesadas y patrones irregulares, al tener más poder el análisis gráfico, se termina por rechazar el cumplimiento de este supuesto. Ahora se validará si la varianza cumple con el supuesto de ser constante.

\subsubsection{Varianza constante}

```{r fig.cap = "Gráfico residuales estudentizados vs valores ajustados"}
res.stud <- round(rstandard(modelo), 4)
yhat <- round(modelo$fitted.values, 4)
plot(yhat, res.stud, xlab = "Valores Ajustados", 
     ylab = "Residuales Estudentizados", main = "Residuales Estudentizados vs Valores Ajustados", pch=20)
abline(h = 0, lty = 2, lwd = 2, col = 2)
```

En el gráfico de residuales estudentizados vs valores ajustados se puede observar que no hay patrones en los que la varianza aumente, decrezca ni un comportamiento que permita descartar una varianza constante, al no haber evidencia suficiente en contra de este supuesto se acepta como cierto. Además es posible observar media 0.


\subsection{Verificación de las observaciones}

```{r}
Cooks.D <- round(cooks.distance(modelo), 4)
hii.value <- round(hatvalues(modelo), 4)
Dffits <- round(dffits(modelo), 4)
base.diagnostico <- data.frame(res.stud, Cooks.D, hii.value, Dffits)
```

Tengan cuidado acá, modifiquen los límites de las gráficas para que tenga sentido con lo que observan en la tabla diagnóstica. También, consideren que en aquellos puntos extremos que identifiquen deben explicar el qué causan los mismos en el modelo.

\subsubsection{Datos atípicos}

```{r fig.cap = "Identificación de datos atípicos"}
with(base.diagnostico,
     plot(res.stud, xlab="Observación", ylab = "Residuales",
          main = "Residuales estudentizados", pch = 20, ylim=c(-5, 5)))
abline(h = 3, col="red", lty = "dashed")
abline(h =- 3, col="red", lty = "dashed")
```

```{r include = F}
atipicos.criterio <- 3
base.diagnostico[base.diagnostico$res.stud > atipicos.criterio | base.diagnostico$res.stud < -atipicos.criterio, ]
```

Como se puede observar en la gráfica anterior, no hay datos atípicos en el conjunto de datos pues ningún residual estudentizado sobrepasa el criterio de $|r_{estud}| > 3$.

\subsubsection{Puntos de balanceo}

```{r fig.cap = "Identificación de puntos de balanceo"}
hii.criterio <- 2*(6/(nrow(datos)))
with(base.diagnostico,
     plot(hii.value, xlab="Observación", ylab = "Valor hii",
          main = "Gráfica de hii para las observaciones", pch = 20, ylim=c(-0.3, 0.3)))
abline(h = hii.criterio, col="red", lty = "dashed")
```

```{r}
base.diagnostico[base.diagnostico$hii.value > hii.criterio, ]
```
Al observar la gráfica de observaciones vs valores $h_{ii}$, donde la línea punteada roja representa el valor $h_{ii} = 2\frac{p}{n}$, se puede apreciar que existen 5 datos del conjunto que son puntos de balanceo según el criterio bajo el cual  $h_{ii} > 2\frac{p}{n}$, los cuales son los presentados en la tabla.

\subsubsection{Puntos  influenciales}

```{r fig.cap="Criterio distancias de Cook para puntos influenciales"}
criterio.cook <- 1
with(base.diagnostico,
     plot(Cooks.D, xlab="Observación", ylab = "Distancia de Cook",
          main = "Gráfica de distancias de Cook", pch = 20, ylim=c(-1.5, 1.5)))
abline(h = criterio.cook, col="red", lty = "dashed")
#base.diagnostico[base.diagnostico$Cooks.D > criterio.cook, ]
```

```{r fig.cap="Criterio Dffits para puntos influenciales"}
Dffits.criterio <- 2* (6/nrow(datos))^(1/2)
with(base.diagnostico,
     plot(Dffits, xlab="Observación", ylab = "Dffit",
          main = "Gráfica de observaciones vs Dffits", pch = 20, ylim=c(-2.1, 1.5)))
abline(h = Dffits.criterio, col="red", lty = "dashed")
abline(h = -Dffits.criterio, col="red", lty = "dashed")
base.diagnostico[base.diagnostico$Dffits > Dffits.criterio | base.diagnostico$Dffits < -Dffits.criterio, ]
```
Como se puede ver,las observaciones ... son puntos influenciales según el criterio de Dffits, el cual dice que para cualquier punto cuyo $|D_{ffit}| > 2\sqrt{\frac{p}{n}}$, es un punto influencial. Cabe destacar también que con el criterio de distancias de Cook, en el cual para cualquier punto cuya $D_{i} > 1$, es un punto influencial, ninguno de los datos cumple con serlo.

\subsection{Conclusión}

Acá como mínimo deben decir si el modelo es válido o no, argumentar por qué y cómo esto se ve afectado por estos puntos extremos.





